{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiegfredLorelle/iskobot-rag-system/blob/main/langchain_with_gemini_build_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgALz5M7I9dQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7751a03-71a9-423a-bb78-594d3f0e2391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.0/384.0 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.2/140.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.7/427.7 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install -q --upgrade google-generativeai langchain-google-genai chromadb pypdf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import textwrap\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "ELCq2M4XJ467"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "CHCjBuPHJ-JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY') # specify in secrets\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "1cb7x-g7KBBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Generation"
      ],
      "metadata": {
        "id": "3NOFOt74X2Gd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name = \"gemini-pro\")\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG_3KsGRKDYU",
        "outputId": "70d856d7-fbde-485a-f49d-52f220ed7200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "genai.GenerativeModel(\n",
              "    model_name='models/gemini-pro',\n",
              "    generation_config={},\n",
              "    safety_settings={},\n",
              "    tools=None,\n",
              "    system_instruction=None,\n",
              "    cached_content=None\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"What are the usecases of LLMs?\")"
      ],
      "metadata": {
        "id": "R-2GbIa-KaUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "i9TTvRUfKmBg",
        "outputId": "78ef14a7-79ec-44ed-f2c0-bc4748e35e74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **Content Generation and Creation:**\n> \n> * **Text generation:** Creating articles, stories, scripts, and other forms of written content\n> * **Image and video generation:** Generating realistic images, videos, and animations\n> * **Music composition:** Generating and composing new music tracks\n> * **Code generation:** Writing and debugging code for various programming languages\n> \n> **Language Processing and Understanding:**\n> \n> * **Natural language processing:** Understanding and generating human-like text\n> * **Machine translation:** Translating text from one language to another\n> * **Text summarization:** Condensing long texts into concise summaries\n> * **Chatbots and virtual assistants:** Engaging in conversations and providing information or assistance\n> \n> **Data Analysis and Exploration:**\n> \n> * **Data summarization:** Extracting key insights and patterns from large datasets\n> * **Text classification:** Categorizing text documents into specific topics or labels\n> * **Fraud detection:** Identifying suspicious or fraudulent activities based on textual data\n> \n> **Search and Recommendation:**\n> \n> * **Search result ranking:** Improving the relevance and quality of search results\n> * **Recommendation systems:** Generating personalized recommendations for products, content, or services\n> * **Knowledge graph construction:** Creating structured representations of knowledge and relationships\n> \n> **Education and Training:**\n> \n> * **Personalized learning:** Tailoring educational content and assessments to individual students\n> * **Language learning:** Assisting learners with reading, writing, and speaking new languages\n> * **Skill development:** Providing interactive simulations and exercises for developing various skills\n> \n> **Healthcare:**\n> \n> * **Medical diagnosis and prediction:** Assisting healthcare professionals in diagnosing and predicting diseases\n> * **Drug discovery and development:** Identifying potential new drug targets and optimizing drug molecules\n> * **Personalized treatment plans:** Tailoring treatment plans to individual patient characteristics\n> \n> **Business and Finance:**\n> \n> * **Market research and analysis:** Gathering and analyzing data to gain insights into market trends\n> * **Financial modeling and forecasting:** Developing financial models to predict future outcomes\n> * **Risk assessment and compliance:** Identifying and mitigating financial risks and ensuring compliance with regulations\n> \n> **Other Use Cases:**\n> \n> * **Customer service:** Providing automated support and answering customer inquiries\n> * **Social media analysis:** Analyzing social media content for sentiment, trends, and engagement\n> * **Entertainment:** Creating interactive games and immersive experiences\n> * **Art and design:** Enhancing creative processes and generating new artistic ideas"
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use LangChain to Access Gemini API"
      ],
      "metadata": {
        "id": "-TbsjM7hK6PR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n"
      ],
      "metadata": {
        "id": "WqdODsdLK8li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",google_api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "vknP_oOWK-k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = llm.invoke(\"What are the usecases of LLMs?\")\n"
      ],
      "metadata": {
        "id": "hvY2YkFoLDO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "ar8KNtZILE47",
        "outputId": "ef34ab32-3b2c-4a7c-c3f2-727470d9d17a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> ## Use Cases of LLMs: A Vast and Growing Landscape\n> \n> Large Language Models (LLMs) are incredibly versatile tools with applications across numerous industries and domains. Here's a glimpse into some of the most prominent use cases:\n> \n> **Content Creation & Communication:**\n> \n> * **Writing & Editing:** Generating articles, blog posts, scripts, marketing materials, summaries, and even poems and code.\n> * **Translation:** Translating text between languages with high accuracy.\n> * **Chatbots & Virtual Assistants:** Providing conversational experiences, answering questions, and offering personalized support.\n> * **Email & Social Media:** Automating responses, composing engaging messages, and optimizing content for different platforms.\n> \n> **Knowledge & Information Retrieval:**\n> \n> * **Search & Information Extraction:**  Improving search results, extracting key information from documents, and answering complex questions.\n> * **Summarization & Analysis:** Generating concise summaries of lengthy texts, analyzing sentiment, and identifying key themes.\n> * **Education & Research:** Providing personalized learning experiences, generating research papers, and assisting in data analysis.\n> \n> **Business & Industry:**\n> \n> * **Customer Service:** Automating customer interactions, resolving queries, and providing personalized recommendations.\n> * **Marketing & Sales:** Creating targeted marketing campaigns, generating product descriptions, and automating sales processes.\n> * **Data Analysis & Insights:**  Analyzing large datasets, identifying patterns, and generating reports.\n> * **Code Generation & Debugging:**  Assisting programmers in writing code, debugging errors, and generating documentation.\n> \n> **Creative Applications:**\n> \n> * **Art & Music Generation:** Creating unique paintings, musical compositions, and even video game levels.\n> * **Storytelling & Scriptwriting:** Generating compelling narratives, developing characters, and creating dialogue.\n> * **Game Development:** Creating interactive dialogues, generating storylines, and enhancing game environments.\n> \n> **Other Emerging Use Cases:**\n> \n> * **Personalized Learning:** Tailoring educational content to individual students' needs and learning styles.\n> * **Healthcare:** Diagnosing diseases, providing personalized treatment plans, and supporting medical research.\n> * **Legal & Finance:** Automating legal research, drafting contracts, and analyzing financial data.\n> \n> **Important Considerations:**\n> \n> While LLMs offer incredible potential, it's essential to consider:\n> \n> * **Bias & Fairness:** LLMs are trained on massive datasets that may reflect societal biases.\n> * **Accuracy & Reliability:** LLMs can sometimes generate incorrect or misleading information.\n> * **Ethical Implications:**  The potential for misuse and the need for responsible development and deployment.\n> \n> **The future of LLMs is constantly evolving. As these models become more sophisticated, we can expect to see even more innovative and impactful use cases emerge.** \n"
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat with Documents using RAG (Retreival Augment Generation)"
      ],
      "metadata": {
        "id": "aVhA3f3GLlQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt -y -qq install tesseract-ocr libtesseract-dev\n",
        "\n",
        "!sudo apt-get -y -qq install poppler-utils libxml2-dev libxslt1-dev antiword unrtf poppler-utils pstotext tesseract-ocr flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig\n",
        "\n",
        "!pip install langchain\n",
        "\n",
        "!pip install -U langchain-community\n",
        "\n",
        "!pip install pdfplumber"
      ],
      "metadata": {
        "id": "h-14UghOLJHA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b30f844-e771-486f-8aa1-f825b10f3303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following additional packages will be installed:\n",
            "  libarchive-dev libleptonica-dev tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libleptonica-dev libtesseract-dev tesseract-ocr\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 6 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 8,560 kB of archives.\n",
            "After this operation, 31.6 MB of additional disk space will be used.\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 123594 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libarchive-dev_3.6.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "Preparing to unpack .../1-libleptonica-dev_1.82.0-3build1_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.82.0-3build1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../2-libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "Preparing to unpack .../3-tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../4-tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../5-tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up libleptonica-dev (1.82.0-3build1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 29.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 123774 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../01-poppler-data_0.4.11-1_all.deb ...\n",
            "Unpacking poppler-data (0.4.11-1) ...\n",
            "Selecting previously unselected package antiword.\n",
            "Preparing to unpack .../02-antiword_0.37-16_amd64.deb ...\n",
            "Unpacking antiword (0.37-16) ...\n",
            "Selecting previously unselected package flac.\n",
            "Preparing to unpack .../03-flac_1.3.3-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking flac (1.3.3-2ubuntu0.2) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../04-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-urw-base35.\n",
            "Preparing to unpack .../05-fonts-urw-base35_20200910-1_all.deb ...\n",
            "Unpacking fonts-urw-base35 (20200910-1) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../06-libgs9-common_9.55.0~dfsg1-0ubuntu5.9_all.deb ...\n",
            "Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Selecting previously unselected package libidn12:amd64.\n",
            "Preparing to unpack .../07-libidn12_1.38-4ubuntu1_amd64.deb ...\n",
            "Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../08-libijs-0.35_0.35-15build2_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../09-libjbig2dec0_0.19-3build2_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../10-libgs9_9.55.0~dfsg1-0ubuntu5.9_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../11-ghostscript_9.55.0~dfsg1-0ubuntu5.9_amd64.deb ...\n",
            "Unpacking ghostscript (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Selecting previously unselected package lame.\n",
            "Preparing to unpack .../12-lame_3.100-3build2_amd64.deb ...\n",
            "Unpacking lame (3.100-3build2) ...\n",
            "Selecting previously unselected package libid3tag0:amd64.\n",
            "Preparing to unpack .../13-libid3tag0_0.15.1b-14_amd64.deb ...\n",
            "Unpacking libid3tag0:amd64 (0.15.1b-14) ...\n",
            "Selecting previously unselected package libmad0:amd64.\n",
            "Preparing to unpack .../14-libmad0_0.15.1b-10ubuntu1_amd64.deb ...\n",
            "Unpacking libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "Preparing to unpack .../15-libopencore-amrnb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../16-libopencore-amrwb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../17-libsox3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../18-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libwavpack1:amd64.\n",
            "Preparing to unpack .../19-libwavpack1_5.4.0-1build2_amd64.deb ...\n",
            "Unpacking libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../20-libsox-fmt-base_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-mp3:amd64.\n",
            "Preparing to unpack .../21-libsox-fmt-mp3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libxslt1-dev:amd64.\n",
            "Preparing to unpack .../22-libxslt1-dev_1.1.34-4ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libxslt1-dev:amd64 (1.1.34-4ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package poppler-utils.\n",
            "Preparing to unpack .../23-poppler-utils_22.02.0-2ubuntu0.5_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Selecting previously unselected package pstotext.\n",
            "Preparing to unpack .../24-pstotext_1.9-6build1_amd64.deb ...\n",
            "Unpacking pstotext (1.9-6build1) ...\n",
            "Selecting previously unselected package sox.\n",
            "Preparing to unpack .../25-sox_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package swig4.0.\n",
            "Preparing to unpack .../26-swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../27-swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package unrtf.\n",
            "Preparing to unpack .../28-unrtf_0.21.10-clean-1_amd64.deb ...\n",
            "Unpacking unrtf (0.21.10-clean-1) ...\n",
            "Setting up unrtf (0.21.10-clean-1) ...\n",
            "Setting up libxslt1-dev:amd64 (1.1.34-4ubuntu0.22.04.1) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Setting up fonts-urw-base35 (20200910-1) ...\n",
            "Setting up lame (3.100-3build2) ...\n",
            "Setting up poppler-data (0.4.11-1) ...\n",
            "Setting up libid3tag0:amd64 (0.15.1b-14) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Setting up flac (1.3.3-2ubuntu0.2) ...\n",
            "Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
            "Setting up libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Setting up antiword (0.37-16) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Setting up ghostscript (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Setting up sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up pstotext (1.9-6build1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.29)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.98)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (3.0.0)\n",
            "Downloading langchain-0.2.12-py3-none-any.whl (990 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: langchain-text-splitters, langchain\n",
            "Successfully installed langchain-0.2.12 langchain-text-splitters-0.2.2\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.1)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.12)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.29)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.98)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.12->langchain-community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.12->langchain-community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain-community) (2.20.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.2.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.11 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.3-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.3 pypdfium2-4.30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import warnings\n",
        "from pathlib import Path as p\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import PDFPlumberLoader\n",
        "\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# restart python kernal if issues with langchain import."
      ],
      "metadata": {
        "id": "7EjS_0qMLwyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n"
      ],
      "metadata": {
        "id": "oBDSBBNRNi8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",google_api_key=GOOGLE_API_KEY,\n",
        "                             temperature=1,convert_system_message_to_human=True)\n"
      ],
      "metadata": {
        "id": "HXXP0LCKN9pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract text from the PDF"
      ],
      "metadata": {
        "id": "6fVI3d0BPaPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_loader = PDFPlumberLoader(\"/content/MOR-Manuscript-RAG.pdf\")  # change to path of your pdf\n",
        "pages = pdf_loader.load_and_split()\n",
        "print(pages[0].page_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Kz7Ek2KPKSy",
        "outputId": "7fbdda94-15dd-4fc4-a4d5-6d07793fa9ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POLYTECHNIC UNIVERSITY OF THE PHILIPPINES\n",
            "PA\n",
            "G E\n",
            "PA\\*\n",
            "ISKOBOT: A LARGE LANGUAGE MODEL-BASED CHATBOT ENHANCED GMEE\n",
            "WITH RETRIEVAL-AUGMENTED GENERATION FOR POLYTECHNIC R\\* G\n",
            "UNIVERSITY OF THE PHILIPPINES – OPEN UNIVERSITY SYSTEM MEEF\n",
            "ROGR\n",
            "EMFA\n",
            "OTR 0\n",
            "MA\n",
            "T 0\n",
            "A Thesis\n",
            "Presented to the Faculty of Computer Engineering\n",
            "Polytechnic University of the Philippines\n",
            "Sta. Mesa, Manila\n",
            "In Partial Fulfilment of the Requirements for the Degree\n",
            "Bachelor of Science in Computer Engineering\n",
            "by\n",
            "AMAD, HAROLD P.\n",
            "DE PADUA, ANGELO MIGUEL N.\n",
            "FABRO, GAEUS CASKIE A.\n",
            "MINA, SIEGFRED LORELLE C.\n",
            "July 2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1nOlnQrZHau",
        "outputId": "c9c48837-e549-45f4-8e78-0ee63731c25d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RAG Pipeline: Embedding + Gemini (LLM)"
      ],
      "metadata": {
        "id": "QQ7OlzvWSRE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
      ],
      "metadata": {
        "id": "xCLmdnHYdoVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n",
        "context = \"\\n\\n\".join(str(p.page_content) for p in pages)\n",
        "texts = text_splitter.split_text(context)"
      ],
      "metadata": {
        "id": "5VCQ2XiUSTOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",google_api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "oenB_PKkSpr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_index = Chroma.from_texts(texts, embeddings).as_retriever(search_kwargs={\"k\":5})\n"
      ],
      "metadata": {
        "id": "zRDgzSjsSZtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    model,\n",
        "    retriever=vector_index,\n",
        "    return_source_documents=True\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "a3CrM0l3Hc__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Ho.\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "C683CMhDHtA8",
        "outputId": "28d7deaf-4a4c-4a32-92f3-b107ea81b7c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The document you provided is a thesis for a Bachelor of Science in Computer Engineering at the Polytechnic University of the Philippines. \\n\\nIt outlines the development of a chatbot system called \"ISKOBOT\" for the Polytechnic University of the Philippines – Open University System (PUP-OUS). \\n\\nThe thesis aims to address the challenges of online learning in the PUP-OUS community, such as communication difficulties and access to information.\\n\\nHere are some key highlights:\\n\\n* **ISKOBOT is designed to be an always available and accessible chatbot for PUP-OUS students and faculty.** \\n* **It uses a Retrieval-Augmented Generation (RAG) model, which enhances the chatbot\\'s ability to provide accurate and up-to-date information by searching and integrating data from relevant sources.**\\n* **The thesis outlines the stages involved in developing ISKOBOT using a prototyping model.**\\n* **It also evaluates the performance of the RAG model in terms of retrieval quality (context relevance, noise robustness), generation quality (answer faithfulness, answer relevance, negative rejection, information integration, counterfactual robustness), and overall user experience.** \\n* **The thesis includes a description of the research instruments used to evaluate ISKOBOT and the statistical methods employed to analyze the data collected.**\\n\\nI hope this summary helps!\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(result[\"result\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "gR9NB2OLIp7I",
        "outputId": "fc78c695-11e1-49d9-f6e3-bcc167b73c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The document you provided is a thesis for a Bachelor of Science in Computer Engineering at the Polytechnic University of the Philippines. \n\nIt outlines the development of a chatbot system called \"ISKOBOT\" for the Polytechnic University of the Philippines – Open University System (PUP-OUS). \n\nThe thesis aims to address the challenges of online learning in the PUP-OUS community, such as communication difficulties and access to information.\n\nHere are some key highlights:\n\n* **ISKOBOT is designed to be an always available and accessible chatbot for PUP-OUS students and faculty.** \n* **It uses a Retrieval-Augmented Generation (RAG) model, which enhances the chatbot's ability to provide accurate and up-to-date information by searching and integrating data from relevant sources.**\n* **The thesis outlines the stages involved in developing ISKOBOT using a prototyping model.**\n* **It also evaluates the performance of the RAG model in terms of retrieval quality (context relevance, noise robustness), generation quality (answer faithfulness, answer relevance, negative rejection, information integration, counterfactual robustness), and overall user experience.** \n* **The thesis includes a description of the research instruments used to evaluate ISKOBOT and the statistical methods employed to analyze the data collected.**\n\nI hope this summary helps!\n"
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"source_documents\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JExbG1VNcDZ",
        "outputId": "77559c53-0c3d-49d4-a3f2-7f8d3a0a5f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='POLYTECHNIC UNIVERSITY OF THE PHILIPPINES\\nPA\\nG E\\nPA\\\\*\\nISKOBOT: A LARGE LANGUAGE MODEL-BASED CHATBOT ENHANCED GMEE\\nWITH RETRIEVAL-AUGMENTED GENERATION FOR POLYTECHNIC R\\\\* G\\nUNIVERSITY OF THE PHILIPPINES – OPEN UNIVERSITY SYSTEM MEEF\\nROGR\\nEMFA\\nOTR 0\\nMA\\nT 0\\nA Thesis\\nPresented to the Faculty of Computer Engineering\\nPolytechnic University of the Philippines\\nSta. Mesa, Manila\\nIn Partial Fulfilment of the Requirements for the Degree\\nBachelor of Science in Computer Engineering\\nby\\nAMAD, HAROLD P.\\nDE PADUA, ANGELO MIGUEL N.\\nFABRO, GAEUS CASKIE A.\\nMINA, SIEGFRED LORELLE C.\\nJuly 2024\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES ii\\n1\\nPPPPAAAA\\nTABLE OF CONTENTS\\nPage GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nTitle Page .................................................................................................................. i MMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nTable of Contents .................................................................................................... ii EEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nList of Tables .......................................................................................................... iv RRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\nList of Figures .......................................................................................................... v\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\nList of Equations .................................................................................................... vi\\nTTTTTTTT 11111111\\nChapter 1: The Problem and its Setting ................................................................. 1\\nIntroduction ................................................................................................................ 1\\nTheoretical Framework .............................................................................................. 3\\nConceptual Framework .............................................................................................. 7\\nStatement of the Problem ........................................................................................ 10\\nScope and Limitations of the Study.......................................................................... 11\\nSignificance of the Study ......................................................................................... 12\\nDefinition of Terms .................................................................................................. 13\\nChapter 2: Review of Literature and Studies ....................................................... 15\\nOnline Learning Challenges .................................................................................... 15\\nChatGPT on Education ............................................................................................ 16\\nRetrieval Augmented Generation ............................................................................. 18\\nSynthesis of the Reviewed Literature and Studies ................................................... 20\\nChapter 3: Methodology ........................................................................................ 22\\nResearch Design ..................................................................................................... 22\\nResearch Locale ...................................................................................................... 23\\nFlowchart of Research Design/Process Flowchart ................................................... 24\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES iii\\n1\\nDescription of Research Instrument Used................................................................ 27\\nPPPPAAAA\\nStatistical Treatment ................................................................................................ 29 GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nDesign Project Flow ................................................................................................. 32 MMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nMultiple Constraints ................................................................................................. 33 EEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nReferences .............................................................................................................. 35 RRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES iv\\n1\\nPPPPAAAA\\nLIST OF TABLES GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nNumber Title Page MMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\n1 Likert Scale Interpretation .................................................................................. 32 EEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nRRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES v\\n1\\nPPPPAAAA\\nLIST OF FIGURES GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nNumber Title Page MMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\n1 Transformer Architecture .................................................................................... 4 EEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\n2 Retrieval-Augmented Generation ........................................................................ 6 RRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\n3 Research Paradigm of the Study ........................................................................ 9\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\n4 A Representative Instance of the RAG Process Applied to Question Answering18\\nTTTTTTTT 11111111\\n5 Screenshot of PwC Learning and Experience Hub from Google Maps ............. 23\\n6 Prototyping Model ............................................................................................. 25\\n7 User flowchart (Single Question) ...................................................................... 26\\n8 Block Diagram of ISKOBOT System ................................................................. 33\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES vi\\n1\\nPPPPAAAA\\nLIST OF EQUATIONS GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nNumber Title Page MMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\n1 Formula of Precision ......................................................................................... 29 EEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\n2 Formula of Recall.............................................................................................. 30 RRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\n3 Formula of Balance Between Precision and Recall ........................................... 30\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\n4 Formula of Mean Reciprocal Rank .................................................................... 30\\nTTTTTTTT 11111111\\n5 Formula of Mean Average Precision ................................................................. 30\\n6 Formula of Accuracy ......................................................................................... 31\\n7 Formula of Rejection Rate ................................................................................ 31\\n8 Formula of Error Detection Rate ....................................................................... 31\\n9 Formula of Error Correction Rate ...................................................................... 31\\n10 Formula for Weighted Mean ............................................................................. 31\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 1\\n1\\nPPPPAAAA\\nGGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nMMMMPPPPPPPPAAAAAAAAEEEE\\nChapter 1 GGGGGGGGRRRRGGGGEEEEEEEE\\nTHE PROBLEM AND ITS SETTING EEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nRRRRRRRRMMMMGGGGGGGGAAAA\\nIntroduction EEEEEEEETTTTFFFFFFFF\\nOOOOOOOO1111RRRRRRRR4444\\nThe Philippines has a long history of grappling with challenges in its education MMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\nsystem. The Philippines’ performance in Programme for International Student\\nAssessment (PISA) reflects these issues. PISA measures the performance of 15 years\\nolds in reading, mathematics and science across various countries. The Philippines\\nranked 78th out of 78 countries in 2018 PISA and 77th out 81 countries in 2022 PISA\\n(Congressional Policy and Budget Research Department, 2024). During the height of\\nthe COVID-19 pandemic, educational institutions in the Philippines were closed, thus\\nthe implementation of online learning. The Philippines responded by strengthening its\\nonline learning platforms (Tria, 2020). Online and distance learning systems introduce\\nan alternative education which alleviates the struggles the educational system faces\\nsuch as finance, disabilities, infrastructure inadequacy, and others.\\nThe Polytechnic University of the Philippines Open University System also\\nknown as PUP-OUS is an approach to tertiary education that empowers learners to\\naccess information and progress at their own pace. Unlike the traditional classroom-\\noriented approach, the Open University System allows students to learn and study\\ntheir respective subjects on the most accessible and time schedules. However, the\\nshift from the traditional approach of the university into the Open University System\\nmodality presents its issues. Communication between the learner and instructors can\\nbe difficult for several reasons. Issues such as misalignment of time or schedule can'),\n",
              " Document(page_content=\"POLYTECHNIC UNIVERSITY OF THE PHILIPPINES 7\\n1\\nOUS community. The proposed system provides an easy-to-use chatbot, tuned and\\nPPPPAAAA\\nenhanced with RAG, to answer general or course specific inquiries from PUP-OUS GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nstudents and faculty. MMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nEEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nConceptual Framework RRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\nThis section presents the research paradigm presented in Figure 3 for the\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\ndevelopment of a Retrieval-Augmented Generation (RAG) Large Language Model\\nTTTTTTTT 11111111\\n(LLM)-based chatbot system. The framework is detailed using an Input-Process-\\nOutput (IPO) model.\\nThe input block in the IPO diagram encompasses essential requirements crucial\\nfor the study's development. These include (1) Knowledge Requirements, covering\\nrelevant theories and concepts necessary for system functionality and compliance; (2)\\nSoftware Requirements, detailing the technology stack essential for implementation;\\nand (3) Hardware Requirements, specifying the necessary components for the\\ndevice's development and operation. These requirements form the foundational\\nelements guiding the research and ensuring comprehensive coverage across\\nknowledge acquisition, software implementation, and hardware integration phases.\\nThe process block in the IPO diagram includes various methodologies designed\\nto advance the research objectives systematically. These methodologies encompass\\nan experimental approach focused on assessing quality scores and enhancing\\ncapabilities related to robustness and integration. Additionally, a descriptive method\\nevaluates software and device performance, while the prototyping model progresses\\nthrough stages from requirements gathering to final implementation, ensuring a\\nstructured approach to development and evaluation.\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 8\\n1\\nThese steps would lead to the title of this research which is “ISKOBOT: A Large\\nPPPPAAAA\\nLanguage Model Chatbot Enhanced with Retrieval Augmented Generation for GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nPolytechnic University of the Philippines – Open University System” as specified in the MMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\noutput block of the research paradigm. Additionally, a feedback loop has been EEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nincorporated, interpreted as a closed system within the research paradigm of the RRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\nstudy.\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 9\\n1\\nPPPPAAAA\\nGGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nMMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nEEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nRRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\nFigure 3. Research Paradigm of the Study\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 10\\n1\\nPPPPAAAA\\nGGGGEEEE\\nStatement of the Problem \\\\\\\\\\\\\\\\** **\\nMMMMPPPPPPPPAAAAAAAAEEEE\\nThe objective of this research is to develop an always available and accessible GGGGGGGGRRRRGGGGEEEEEEEE\\nEEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nchatbot for the Polytechnic University of The Philippines – Open University System MMMMMMMMOOOOEEEEEEEERRRR\\nRRRRRRRRMMMMGGGGGGGGAAAA\\n(PUP-OUS) community that can answer general inquiries and course-specific\\nEEEEEEEETTTTFFFFFFFF\\nOOOOOOOO1111RRRRRRRR4444\\nquestions reliably.\\nMMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\nHowever, several key issues need to be addressed in the development and\\nimplementation of ISKOBOT: A Large Language Model Chatbot Enhanced with\\nRetrieval Augmented Generation for Polytechnic University of the Philippines – Open\\nUniversity System:\\n1. What are the stages involved in the development process of ISKROBOT using\\nthe prototyping model?\\n2. How does the RAG model of ISKROBOT perform in terms of retrieval and\\ngeneration quality, specifically considering:\\n2.1. Context Relevance,\\n2.2. Answer Faithfulness,\\n2.3. Answer Relevance,\\n2.4. Noise Robustness,\\n2.5. Negative Rejection,\\n2.6. Information Integration, and\\n2.7. Counterfactual Robustness?\\n3. What is the level of acceptability among the respondents (PUP-OUS students\\nand faculty) regarding the assessment of ISKROBOT according to the ISO/IEC\\nCommented [GF1]:\\n25010:2023 standard in terms of:\\npwede limit sa RAG Triad\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 11\\n1\\n3.1. Functional suitability,\\nPPPPAAAA\\n3.2. Reliability, and GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\n3.3. Interaction Capability? MMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nEEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nScope and Limitations of the Study RRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\nThe study will focus on the courses offered within the Polytechnic University of\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\nthe Philippines—Open University System. The following will include Baccalaureate\\nTTTTTTTT 11111111\\nPrograms, Post Baccalaureate Programs, and Advanced Studies. Baccalaureate\\nPrograms that will be covered are Bachelor in Public Administration (BPA), Bachelor\\nof Arts in Broadcasting (BABR), Bachelor of Science in Business Administration major\\nin Marketing Management (BSBAMM), Bachelor of Science in Business\\nAdministration major in Human Resource Management (BSBAHRM), Bachelor of\\nScience in Entrepreneurship (BSENTREP), Bachelor of Science in Office\\nAdministration (BSOA), Bachelor of Science in Tourism Management (BSTM). Post\\nBaccalaureate Program covers Post Baccalaureate Diploma in Information\\nTechnology. Advanced Studies covers Doctor in Business Administration (DBA),\\nDoctor in Education Management (DEM), Doctor in Engineering Management\\n(D.Eng.), Doctor in Public Administration (DPA), Master of Science in Construction\\nManagement (MSCM), Master in Business Administration (MBA), Master in\\nCommunication (MC), Master in Education Management (MEM), Master in Information\\nTechnology (MIT), and Master in Public Administration (MPA). The study also uses\\nlearning materials that cover the stated academic programs that are offered within the\\nOpen University System. Learning materials include actual learning modules for\\nsubjects within specific courses, general guidelines provided by course departments,\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 12\\n1\\netc. The study also used general inquiry materials. The general inquiry materials\\nPPPPAAAA\\ninclude the Polytechnic University of the Philippines Student Handbook and its multiple GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nversions and revisions. Materials related to enrollment and university rules and MMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nregulations are also used in the study. The project also uses previous inquiries from EEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nthe user as a cross-reference for accurate and better responses. RRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\nThe study will not include courses that are not part of the Polytechnic University\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\nof the Philippines Open University System Program. This also means that courses\\nTTTTTTTT 11111111\\nincluded in the main program of the Polytechnic University of the Philippines that are\\nnot included in the Open University System program are also not included in the data\\nthat will be used to train the chatbot. However, materials that are related to courses\\noffered by the Open University System that come from the main Polytechnic University\\nof the Philippines Program will be included. The materials will not be included to\\nincrease the accuracy of the chatbot when answering inquiries and inputs from the\\nuser. Additionally, student records are also not included and will not be used as the\\nrecords are confidential to the enrollee.\\nSignificance of the Study\\nPolytechnic University of the Philippines—Open University System. Improved\\naccessibility to learning and teaching materials. Advancements in data and AI-driven\\ntechnology within its academy and community.\\nStudents. Easily accessible learning materials and a place to answer basic inquiries\\nof the learners will help enhance the learning capability of the students within the Open\\nUniversity System.\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 13\\n1\\nFaculty. Machine learning-aided teaching can improve the quality of education that\\nPPPPAAAA\\nthe faculty of the Open University System will impart to the learners. The study can GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nhelp improve assisting remote learners by utilizing artificial intelligence. MMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nEEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nFuture Researchers. The system and study will also benefit future researchers who MMMMMMMMOOOOEEEEEEEERRRR\\nRRRRRRRRMMMMGGGGGGGGAAAA\\nare interested in or will be taking the same course or topic for their own research to EEEEEEEETTTTFFFFFFFF\\nOOOOOOOO1111RRRRRRRR4444\\nbuild on as references.\\nMMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\nDefinition of Terms\\n• Programme for International Student Assessment (PISA): A global survey\\nconducted by the OECD that evaluates the knowledge and skills of 15-year-\\nolds in reading, mathematics, and science across participating countries every\\nthree years.\\n• Polytechnic University of the Philippines Open University System (PUP-OUS):\\nAn educational platform offering flexible, distance learning options that allow\\nstudents to study at their own pace and schedule, as opposed to the traditional,\\nclassroom-based approach.\\n• Open University System: A non-traditional educational approach providing\\nflexible access to education, allowing students to engage in coursework\\nremotely and at their convenience, without the need for a physical classroom\\npresence.\\n• Online and Distance Learning (ODL): Educational methods that utilize digital\\nplatforms to facilitate learning remotely, allowing students to engage in\\ncoursework from various locations and at flexible times, rather than in a\\ntraditional classroom setting.\"),\n",
              " Document(page_content='POLYTECHNIC UNIVERSITY OF THE PHILIPPINES 2\\n1\\npresent themselves, especially in cases where the instructor and the learner are in\\nPPPPAAAA\\ndifferent time zones (Carambas & Espique, 2023). Another issue comes in the aspect GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nof unexpected emergencies that can affect both the schedule of the instructor and the MMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nlearner (Ferri et al., 2020). Additionally, readily available resources for general EEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\ninformation and reliable learning materials can be hard to find or not as readily RRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\naccessible (Malbas et al., 2023). The challenges mentioned above can be alleviated\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\nby offering a chatbot system, which is currently lacking in the community, specifically\\nTTTTTTTT 11111111\\ndeveloped to address general inquiries and course-specific questions tailored to the\\nPolytechnic University of the Philippines Open University System community.\\nFurthermore, by enhancing the Large Language Model with Retrieval Augmented\\nGeneration or RAG techniques, the chatbot can reply to the user with the most\\naccurate and up-to-date information by cross-referencing different materials that are\\npresent within the database.\\nThe proposed study also aligns with several Sustainable Development Goals\\n(SDGs) outlined by the United Nations. Goal 4: Quality Education. By promoting\\neffective learning and an accessible learning environment. The study helps promote\\nquality education within the country especially for those who cannot afford the\\ntraditional modality of tertiary education. Goal 8: Decent Work and Economic Growth.\\nImprovement within the education program of the country will pay off when it comes to\\neconomic growth. Effective learners grow into effective workers and therefore\\ncontribute much more effectively to society. Goal 9: Industry, Innovation and\\nInfrastructure. Implementation of Large Language Models and Retrieval Augmented\\nGeneration and overall, the use of artificial intelligence and machine learning\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 3\\n1\\ntechnology to improve the Open University System experience for both the enrollee\\nPPPPAAAA\\nand the faculty promotes innovation within the education industry. GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nMMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nEEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nTheoretical Framework MMMMMMMMOOOOEEEEEEEERRRR\\nRRRRRRRRMMMMGGGGGGGGAAAA\\nLarge Language models (LLMs)\\nEEEEEEEETTTTFFFFFFFF\\nOOOOOOOO1111RRRRRRRR4444\\nLLMs are a subset of deep learning and natural language processing (NLP) that\\nMMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\nintersects with generative AI. LLMs are models capable of processing and generating\\nhuman-like texts. They are trained in large amounts of textual data typically in a\\ntransformer, a deep neural network architecture.\\nTransformer outperforms recurrent neural networks (RNNs), long short-term\\nmemory networks (LSTMs) and other deep learning architecture for sequential data\\nbecause of its attention mechanisms (Vaswani et al., 2023). The self-attention\\nmechanism implemented in the encoder-decoder structure of a transformer, allows the\\nmodel to consider the context of the entire sequential data, rather than only the token\\nor word before it. As shown in Figure 1, the process of the embedded input text\\nproceeds into the encoder and then forwarded to the decoder before outputting the\\nfinal sequence.\\nGeneric LLMs are designed to perform general language related tasks such as\\nresponding and translating. The system proposed in this paper utilizes LLMs to act as\\na chatbot to respond to inquiries. The LLM is tuned to a specific domain by learning\\nspecific relevant information on PUP-OUS.\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 4\\n1\\nPPPPAAAA\\nGGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nMMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nEEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nRRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\nFigure 1. Transformer Architecture (Nyandwi, 2023)\\nConversational Artificial Intelligence (AI)\\nConversational AI is a sub-field of artificial intelligence (AI) that uses natural\\nlanguage processing (NLP), large language models (LLMs), and machine learning\\n(ML) to mimic human conversation. It achieves this by understanding the human\\nlanguage and generating a meaningful response. The recent success in\\nconversational AI led to the rise of conversational AI chatbots such as ChatGPT,\\nGemini, and Claude (Lin et al., 2023). Other common use cases for conversational AI\\naside from chatbots are virtual assistants, and speech-based and text-based AI\\nagents. The system proposed in this paper leverages a conversational AI chatbot to\\nprovide instant responses to inquiries related to PUP-OUS.\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 5\\n1\\nInformation Retrieval (IR)\\nPPPPAAAA\\nIR is a branch of computer science that overlaps with database technology and GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nnatural language processing (NLP). It deals with searching, collecting, or browsing MMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\ninformation in documents, databases, and other resources like research papers and EEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nelectronic textbooks. IR works by indexing. Index is tag that could be a numerical value RRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\nor label attached to documents, words, or concepts that can later be used to search\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\nor retrieve them efficiently.\\nTTTTTTTT 11111111\\nA well-known example of IR systems focused on web information is Google\\n(Hjørland, 2021). Web crawlers systematically browse the web to index pages for the\\nsearch engine. A simpler approach is web scraping. It extracts data from only a\\nspecific-domain or website. The system proposed in this paper extracts up-to-date\\ndata from the official PUP-OUS webpages regularly through web scraping. The\\nextracted data are stored in a vector database to act as the knowledge base of the\\nRetrieval Augmented Generation (RAG) system.\\nRAG is an AI framework that combines IR systems and generative LLMs. RAG\\ngives an LLM a reference point through its knowledge base. In Figure 2, The prompt\\nis queried to the knowledge base or sources to find relevant information. Found\\nrelevant information is added to the input given to the LLMs. This grounds the LLM\\nreducing the likelihood of hallucinations or generating factually incorrect response. The\\nvector database in RAG can also be updated frequently to ensure that the LLM has\\naccess to up-to-date information. The system proposed in this paper utilizes RAG with\\na knowledge base specifically tailored to PUP-OUS information and integrates it with\\nan LLM to create a chatbot system for PUP-OUS community.\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 6\\n1\\nPPPPAAAA\\nGGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nMMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nEEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nRRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\nFigure 2. Retrieval-Augmented Generation (Huang et al., 2023)\\nOpen and Distance Learning (ODL)\\nODL is a field of education that prioritizes making education opportunities\\naccessible regardless of time and location constraints. It aims to overcome barriers in\\ntraditional education such as finances, age, disabilities, or schedule conflicts. ODL has\\nbeen growing rapidly due to the development of technologies related to the Internet\\nsuch as online platform for learning and video conferencing tools (Saravanakumar,\\n2023). ODL provides a flexible alternative to traditional education classroom-based\\nlearning. Most educational institutions throughout the world adopted an ODL system\\nduring the height of the COVID-19 pandemic (Clyde, 2021). In the Philippines, several\\nuniversities including the University of the Philippines (UP), Polytechnic University of\\nthe Philippines (PUP), and Mariano Marcos State University (MMSU) have\\nimplemented “Open University System”, an ODL system integrated within their\\ninstitution. This paper proposes a system to improve the overall experience for PUP-'),\n",
              " Document(page_content='POLYTECHNIC UNIVERSITY OF THE PHILIPPINES 32\\n1\\nWhere 𝑤 is the weight of each rating, 𝑥 is the frequency for each rating and 𝑛\\n𝑖 𝑖\\nPPPPAAAA\\nis the number of ratings. The mean weight for each question in the questionnaire is GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\ninterpreted using the Likert scale in Table 1. MMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nEEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nRating Weighted Mean Interpretation RRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\n4 3.51 – 4.00 Highly Acceptable\\nOOOOOOOO1111RRRRRRRR4444\\n3 2.51 – 3.50 Acceptable MMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\n2 1.51 – 2.50 Unacceptable\\n1 1.00 – 1.50 Highly Unacceptable\\nTable 1. Likert Scale Interpretation\\nDesign Project Flow\\nFigure 8 depicts the proposed project flow of ISKOBOT. A user initiates the\\ninteraction by typing an inquiry using the virtual keyboard or speaking into a\\nmicrophone. The inquiry received by the microcontroller goes through embedding,\\nthen formulates an API request to retrieve relevant information from the vector\\ndatabase. This database stores vectorize information on PUP-OUS, including files and\\nscraped data from their official webpage. The relevant information along with the\\noriginal inquiry is processed by the LLM to generate a response accordingly. The LCD\\nscreen displays the response.\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 33\\n1\\nPPPPAAAA\\nGGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nMMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nEEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nRRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\nFigure 8. Block Diagram of ISKOBOT System\\nMultiple Constraints\\n• Memory Usage: Large Language Models can be memory-intensive, requiring\\nsubstantial RAM and VRAM when processing large datasets and storing the\\nmodel’s data.\\n• Hardware Requirements: High computational and processing power is often\\nrequired when running Large Language Models with Retrieval Augmented\\nGeneration. GPUs and TPUs are necessary for both training and interference.\\n• Inference Time: Implementing Retrieval Augmented Generation into Large\\nLanguage Models can introduce latency which then impacts real-time\\napplications of the trained model.\\n• Network Latency: retrieval of components can be affected by network latency\\nespecially with remote databases and APIs that will be then used in the\\napplication.\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 34\\n1\\n• Operational Costs: Setting up remote databases and cloud servers can\\nPPPPAAAA\\nincrease the operational costs and maintenance costs of running the program.\\nGGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nMMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nEEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nRRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 35\\n1\\nPPPPAAAA\\nGGGGEEEE\\nReferences \\\\\\\\\\\\\\\\** **\\nMMMMPPPPPPPPAAAAAAAAEEEE\\nAbendan. (2023). In Retrospect and Prospect: An Analysis of the Philippine GGGGGGGGRRRRGGGGEEEEEEEE\\nEducational System and the Impact of K-12 Implementation. Excellencia: EEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nInternational Multi-Disciplinary Journal of Education (2994-9521), 1(4), 283–294. MMMMMMMMOOOOEEEEEEEERRRR\\nhttps://multijournals.org/index.php/excellencia-imje/article/view/65 RRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\nBao, W. (2020). COVID-19 and online teaching in higher education: A case study of\\nOOOOOOOO1111RRRRRRRR4444\\nPeking University. Human Behavior and Emerging Technologies, 2(2), 113-115.\\nMMMMMMMMAAAAAAAA\\nRetrieved from https://psycnet.apa.org/record/2020-77530-001.\\nTTTTTTTT 11111111\\nCarambas, J., & Espique, F. P. (2023). Lived experiences of teachers and students in\\ndistance education: shift from traditional to online learning. ResearchGate;\\nAcademy of Cognitive and Natural Sciences.\\nhttps://www.researchgate.net/publication/374600790_Lived_experiences_of_tea\\nchers_and_students_in_distance_education_shift_from_traditional_to_online_le\\narning\\nChen, J., Lin, H., Han, X., & Sun, L. (2024). Benchmarking Large Language Models\\nin Retrieval-Augmented Generation. Proceedings of the AAAI Conference on\\nArtificial Intelligence, 38(16), 17754–17762.\\nhttps://doi.org/10.1609/aaai.v38i16.29728\\nClyde, J. (2021). Adapting to the culture of “new normal”: an emerging response to\\nCOVID-19. Journal of Public Health, 43(2), e344–e345.\\nhttps://doi.org/10.1093/pubmed/fdab057\\nCongressional Policy and Budget Research Department. (2024). Philippines’\\nPerformance in the 2018 and 2022 PISA.\\nhttps://cpbrd.congress.gov.ph/images/PDF%20Attachments/Facts%20in%20Fig\\nures/FF2024-11_Philippines_Perf_in_the_2018_and_2021_PISA.pdf\\nDe Oliveira, G., Rodrigues, L. M. S., & Schmidt, R. (2021). Teaching in the Time of\\nPandemic: Quality Education Practices and Challenges for Teachers in Online\\nLearning. Informing Science: The International Journal of an Emerging\\nTransdiscipline, 24, 59-79. Retrieved from\\nhttps://www.informingscience.org/Publications/4784.\\nEs, S., James, J., Espinosa-Anke, L., & Schockaert, S. (2023). Ragas: Automated\\nevaluation of retrieval augmented generation. arXiv preprint arXiv:2309.15217.\\nFerri, F., Patrizia Grifoni, & Guzzo, T. (2020). Online Learning and Emergency Remote\\nTeaching: Opportunities and Challenges in Emergency Situations. Societies,\\n10(4), 86–86. https://doi.org/10.3390/soc10040086\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 36\\n1\\nHassan, M. (2021). Online Teaching Challenges during COVID-19 Pandemic.\\nInternational Journal of Information and Education Technology. 11. 41-46. PPPPAAAA\\n10.18178/ijiet.2021.11.1.1487. GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nHjørland, B. (2021). Information Retrieval and Knowledge Organization: A Perspective MMMMPPPPPPPPAAAAAAAAEEEE\\nfrom the Philosophy of Science. Information, 12(3), 135–135. GGGGGGGGRRRRGGGGEEEEEEEE\\nhttps://doi.org/10.3390/info12030135 EEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nHuang X., Chadha R., Singh H., Khetan A., Dadarkar M., & Ulrich K. (2023). Amazon\\nRRRRRRRRMMMMGGGGGGGGAAAA\\nWeb Services. https://aws.amazon.com/blogs/machine-learning/question-\\nEEEEEEEETTTTFFFFFFFF\\nanswering-using-retrieval-augmented-generation-with-foundation-models-in-\\nOOOOOOOO1111RRRRRRRR4444\\namazon-sagemaker-jumpstart/\\nMMMMMMMMAAAAAAAA\\nIsmail, N. A., & Razak, N. A. (2021). Challenges Faced by Students Learning TTTTTTTT 11111111\\nProgramming Subjects in an ODL Environment at UiTM Pahang. Retrieved from\\nThe challenges of learning programming subject in online distance learning (ODL)\\nenvironment at UiTM Pahang / Nor Zalina Ismail and Mohd Rizal Razak - UiTM\\nInstitutional Repository\\nKalla, D., & Smith, N. (2023, March 1). Study and Analysis of Chat GPT and its Impact\\non Different Fields of Study. Papers.ssrn.com.\\nhttps://papers.ssrn.com/sol3/papers.cfm?abstract_id=4402499\\nLewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., ... & Kiela, D.\\n(2020). Retrieval-augmented generation for knowledge-intensive nlp tasks.\\nAdvances in Neural Information Processing Systems, 33, 9459-9474.\\nLin, C.-C., Huang, A., & Stephen. (2023). A Review of AI-Driven Conversational\\nChatbots Implementation Methodologies and Challenges (1999–2022).\\nSustainability. 15. 4012. https://doi.org/10.3390/su15054012\\nMartineau, K. (2023). retrieval-augmented-generation-RAG. Retrieved from IBM:\\nhttps://research.ibm.com/blog/retrieval-augmented-generation-RAG\\nNyandwi, J. (2023). The Transformer Blueprint: A Holistic Guide to the Transformer\\nNeural Network Architecture. Deep Learning Revision.\\nhttps://deeprevision.github.io/posts/001-transformer/\\nOpara, E., Mfon-Ette Theresa, A., & Aduke, T. C. (2023, March 1). ChatGPT for\\nTeaching, Learning and Research: Prospects and Challenges. Social Science\\nResearch Network.\\nhttps://papers.ssrn.com/sol3/papers.cfm?abstract_id=4375470\\nPark, H., & Ahn, D. (2024). The Promise and Peril of ChatGPT in Higher Education:\\nOpportunities, Challenges, and Design Implications.\\nhttps://doi.org/10.1145/3613904.3642785'),\n",
              " Document(page_content='POLYTECHNIC UNIVERSITY OF THE PHILIPPINES 25\\n1\\nPPPPAAAA\\nGGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nMMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nEEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nRRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\nFigure 6. Prototyping Model\\nFigure 6 illustrates the user flowchart for interacting with ISKOBOT, a Retrieval-\\nAugmented Generation (RAG) application, handling a single question. The interaction\\nbegins when a user initiates a session (Start) by asking a question. ISKOBOT then\\nprocesses this question by leveraging its large language model capabilities\\naugmented with retrieval mechanisms to generate a relevant and accurate response.\\nThe system presents this response to the user, at which point the flowchart includes a\\ndecision node: \"Does the response satisfy the user\\'s question?\" If the response is\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 26\\n1\\nsatisfactory, the process concludes (End). However, if the user finds the response\\nPPPPAAAA\\ninsufficient or requires further clarification, they are prompted to refine their question. GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nThis refined question is then processed again by ISKOBOT, continuing the cycle until MMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nthe user is satisfied with the response, ultimately leading to the end of the interaction. EEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nRRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\nFigure 7. User flowchart (Single Question)\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 27\\n1\\nPPPPAAAA\\nGGGGEEEE\\nDescription of Research Instrument Used \\\\\\\\\\\\\\\\** **\\nMMMMPPPPPPPPAAAAAAAAEEEE\\nPrototype Evaluation. GGGGGGGGRRRRGGGGEEEEEEEE\\nEEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nThe proponents will develop a research instrument designed to evaluate the MMMMMMMMOOOOEEEEEEEERRRR\\nRRRRRRRRMMMMGGGGGGGGAAAA\\nsystem prototype and address the third specific research question. This evaluation tool\\nEEEEEEEETTTTFFFFFFFF\\nOOOOOOOO1111RRRRRRRR4444\\nencompasses three primary criteria, based on the ISO/IEC 25010:2023 standard:\\nMMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\nfunctional suitability, reliability, and interaction capability.\\nFunctional suitability pertains to the ability of the product to deliver functions that\\nsatisfy both stated and implied needs of the intended users when used under specified\\nconditions. It involves assessing whether the system performs essential tasks such as\\ndata entry, report generation, and information retrieval, which are crucial for fulfilling\\nthe users\\' requirements and enhancing operational efficiency.\\nReliability refers to the product\\'s capability to perform specified functions under\\ngiven conditions for a certain period without interruptions or failures. This criterion\\nevaluates the system\\'s consistency and dependability in processing and maintaining\\ndata, ensuring continuous and error-free operation. It emphasizes the system\\'s\\nrobustness in handling tasks like real-time data processing and transaction recording\\nwithout experiencing downtime or data loss.\\nInteraction capability measures the system\\'s effectiveness in facilitating\\ncommunication between users and the system via the user interface, enabling the\\ncompletion of intended tasks. This criterion assesses how intuitively and efficiently\\nusers can navigate the system, perform operations, and receive feedback, ensuring\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 28\\n1\\nthat the system\\'s interface supports a seamless user experience. It focuses on aspects\\nPPPPAAAA\\nlike interface design, user guidance, and feedback mechanisms that contribute to a GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nuser-friendly and responsive interaction environment. MMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nEEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nRAG Model Evaluation. MMMMMMMMOOOOEEEEEEEERRRR\\nRRRRRRRRMMMMGGGGGGGGAAAA\\nIn this research, the proponents will explore various evaluation frameworks to EEEEEEEETTTTFFFFFFFF\\nOOOOOOOO1111RRRRRRRR4444\\nassess the metrics of RAG models across two key evaluation aspects: quality scores\\nMMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\nand required abilities. The contemporary evaluation practices of RAG models\\nemphasize three primary quality scores—context relevance, answer faithfulness, and\\nanswer relevance—each crucial in evaluating the efficiency of information retrieval and\\ngeneration processes. Context relevance evaluates the precision and specificity of\\nretrieved contexts, minimizing extraneous content and processing costs. Answer\\nfaithfulness ensures generated answers remain consistent with retrieved information,\\navoiding contradictions. Answer relevance demands generated answers directly\\naddress posed questions, effectively meeting core inquiries.\\nAdditionally, RAG model evaluation includes four critical abilities—noise\\nrobustness, negative rejection, information integration, and counterfactual\\nrobustness—essential for adaptability and efficiency. Noise robustness evaluates the\\nmodel\\'s capacity to handle noisy, question-related documents lacking substantive\\ninformation. Negative rejection assesses the model\\'s discretion in refraining from\\nanswering, when necessary, knowledge is absent in retrieved documents. Information\\nintegration measures the model\\'s ability to synthesize information from multiple\\nsources to address complex queries. Counterfactual robustness tests the model\\'s\\ncapability to identify and disregard inaccuracies within documents, despite potential\\nmisinformation\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 29\\n1\\nBy employing these instruments, the researchers ensure a comprehensive\\nPPPPAAAA\\nevaluation of the prototype, aligning it with the latest standards to effectively meet GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nusers\\' needs, maintain high performance, and enhance user satisfaction. This holistic MMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\napproach integrates various evaluation aspects to assess RAG models thoroughly. EEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\nContext relevance and noise robustness primarily evaluate retrieval quality, ensuring RRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\nprecision and managing noise in question-related documents. Simultaneously, answer\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\nfaithfulness, answer relevance, negative rejection, information integration, and\\nTTTTTTTT 11111111\\ncounterfactual robustness collectively gauge the quality of generation processes,\\nensuring consistency, relevance, discernment in response, synthesis of information,\\nand accuracy in recognizing and mitigating inaccuracies. This comprehensive\\nevaluation framework aims to optimize the prototype\\'s functionality and usability\\nacross diverse scenarios and user expectations.\\nStatistical Treatment\\nThis section details the statistical method employed to analyze the data\\ncollected during the evaluation of ISKOBOT. The overall effectiveness of the system\\nis evaluated on three (3) aspects: evaluation of the RAG system performance,\\nresponses generated by LLM, and experience of respondents. RAG system\\nperformance was evaluated using metrics such as precision, recall, F1 score, mean\\nreciprocal rank (MRR), and mean average precision (MAP).\\n𝑇𝑟𝑢𝑒 𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒\\n𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛=\\n𝑇𝑟𝑢𝑒 𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒+𝐹𝑎𝑙𝑠𝑒 𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒\\nEquation 1. Formula of Precision\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 30\\n1\\n𝑇𝑟𝑢𝑒 𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒\\n𝑅𝑒𝑐𝑎𝑙𝑙= PPPPAAAA\\n𝑇𝑟𝑢𝑒 𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒+𝐹𝑎𝑙𝑠𝑒 𝑁𝑒𝑔𝑎𝑡𝑖𝑣𝑒\\nGGGGEEEE\\nEquation 2. Formula of Recall \\\\\\\\\\\\\\\\** **\\nMMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nEEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\n𝐹1\\n𝑠𝑐𝑜𝑟𝑒=2⋅𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 ⋅𝑅𝑒𝑐𝑎𝑙𝑙 MMMMMMMMOOOOEEEEEEEERRRR\\n𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛+ 𝑅𝑒𝑐𝑎𝑙𝑙 RRRRRRRRMMMMGGGGGGGGAAAA\\nEEEEEEEETTTTFFFFFFFF\\nEquation 3. Formula of Balance Between Precision and Recall\\nOOOOOOOO1111RRRRRRRR4444\\nMMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\n𝑄\\n1 1\\n𝑀𝑅𝑅= ∑\\n𝑄 𝑟𝑎𝑛𝑘\\n𝑞\\n𝑞=1\\nEquation 4. Formula of Mean Reciprocal Rank\\nWhere 𝑄 is the number of queries, and 𝑟𝑎𝑛𝑘 is the rank of the first relevant\\n𝑞\\ndocument.\\n𝑄\\n1\\n𝑀𝐴𝑃= ∑𝐴𝑣𝑒𝑟𝑎𝑔𝑒 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛(𝑞)\\n𝑄\\n𝑞=1\\nEquation 5. Formula of Mean Average Precision\\nWhere 𝑄 is the number of queries, and 𝑞 is the average precision for the query.\\nThe metrics used to evaluate the Large Language Model (LLM) responses are\\nbased on the research paper \"Benchmarking Large Language Models in Retrieval-\\nAugmented Generation\" (Chen et al., 2024). Accuracy is measured by evaluating the\\nfactual correctness of the LLM\\'s response content through word matching with the\\ncorrect answer. Rejection rate is measured by providing the LLM with an unrelated\\ninquiry and assessing its ability to acknowledge that inquiry is irrelevant. Error\\n\\nPOLYTECHNIC UNIVERSITY OF THE PHILIPPINES 31\\n1\\ndetection rate is measured by giving factually incorrect information and expecting the\\nPPPPAAAA\\nLLM to detect it. Error correction rate, similar to error detection rate, expects the LLM GGGGEEEE\\n\\\\\\\\\\\\\\\\** **\\nto correct the factually incorrect information. MMMMPPPPPPPPAAAAAAAAEEEE\\nGGGGGGGGRRRRGGGGEEEEEEEE\\nEEEE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\********FFFF\\nMMMMMMMMOOOOEEEEEEEERRRR\\n𝐶𝑜𝑟𝑟𝑒𝑐𝑡 𝑀𝑎𝑡𝑐ℎ𝑒𝑠\\n𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦= ⋅100\\nRRRRRRRRMMMMGGGGGGGGAAAA\\n𝐸𝑥𝑝𝑒𝑐𝑡𝑒𝑑 𝑀𝑎𝑡𝑐ℎ𝑒𝑠 EEEEEEEETTTTFFFFFFFF\\nOOOOOOOO1111RRRRRRRR4444\\nEquation 6. Formula of Accuracy\\nMMMMMMMMAAAAAAAA\\nTTTTTTTT 11111111\\n𝐶𝑜𝑟𝑟𝑒𝑐𝑡 𝑅𝑒𝑗𝑒𝑐𝑡𝑖𝑜𝑛𝑠\\n𝑅𝑒𝑗𝑒𝑐𝑡𝑖𝑜𝑛 𝑟𝑎𝑡𝑒= ⋅100\\n𝐸𝑥𝑝𝑒𝑐𝑡𝑒𝑑 𝑅𝑒𝑗𝑒𝑐𝑡𝑖𝑜𝑛𝑠\\nEquation 7. Formula of Rejection Rate\\n𝐸𝑟𝑟𝑜𝑟𝑠 𝐷𝑒𝑡𝑒𝑐𝑡𝑒𝑑\\n𝐸𝑟𝑟𝑜𝑟 𝑑𝑒𝑡𝑒𝑐𝑡𝑖𝑜𝑛 𝑟𝑎𝑡𝑒= ⋅100\\n𝐸𝑥𝑝𝑒𝑐𝑡𝑒𝑑 𝐸𝑟𝑟𝑜𝑟𝑠\\nEquation 8. Formula of Error Detection Rate\\n𝐶𝑜𝑟𝑟𝑒𝑐𝑡 𝐶𝑜𝑟𝑟𝑒𝑐𝑡𝑖𝑜𝑛𝑠\\n𝐸𝑟𝑟𝑜𝑟 𝑐𝑜𝑟𝑟𝑒𝑐𝑡𝑖𝑜𝑛 𝑟𝑎𝑡𝑒= ⋅100\\n𝐸𝑥𝑝𝑒𝑐𝑡𝑒𝑑 𝐶𝑜𝑟𝑟𝑒𝑐𝑡𝑖𝑜𝑛𝑠\\nEquation 9. Formula of Error Correction Rate\\nData gathered from the survey are used to evaluate the experience of the\\nrespondents when using the system. The weighted mean of the respondents’ answer\\nis determined for each item in the survey.\\n∑𝑛 𝑤𝑥\\n𝑊𝑒𝑖𝑔ℎ𝑡𝑒𝑑 𝑚𝑒𝑎𝑛= x̄= 𝑖=1 𝑖 𝑖\\n∑𝑛 𝑤\\n𝑖=1 𝑖\\nEquation 10. Formula for Weighted Mean')]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)# Run chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    model,\n",
        "    retriever=vector_index,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")\n"
      ],
      "metadata": {
        "id": "TGFjxwzcUb02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is ISKOBOT?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "og-CJ7iaMYJe",
        "outputId": "9af258f2-f747-4884-b92a-517c1c6160f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ISKOBOT is a Retrieval-Augmented Generation (RAG) application that uses large language model capabilities to generate relevant and accurate responses to user questions.  Thanks for asking! \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(result[\"result\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "BwZpAwFWMbor",
        "outputId": "a195b0f4-6b4f-4d8d-a384-0e67f445d65f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "ISKOBOT is a Retrieval-Augmented Generation (RAG) application that uses large language model capabilities to generate relevant and accurate responses to user questions.  Thanks for asking! \n"
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who is Harold?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "Markdown(result[\"result\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "CFNBXo0kJKkA",
        "outputId": "8317b4f5-f0a3-4770-c69c-708f675c6eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Harold P. Amad is one of the authors of the thesis \"ISKOBOT: A LARGE LANGUAGE MODEL-BASED CHATBOT ENHANCED WITH RETRIEVAL-AUGMENTED GENERATION FOR POLYTECHNIC UNIVERSITY OF THE PHILIPPINES – OPEN UNIVERSITY SYSTEM\". \n\nThanks for asking! \n"
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}